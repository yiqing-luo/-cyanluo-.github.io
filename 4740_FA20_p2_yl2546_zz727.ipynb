{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNdFlbLJoUXM"
   },
   "source": [
    "# Project 2: Span Identification with Sequence Labeling Models\n",
    "## CS4740/5740 Fall 2020\n",
    "\n",
    "### Project Submission Due: Oct 23rd\n",
    "Please submit **pdf file** of this notebook on **Gradescope**, and **ipynb** on **CMS**. For instructions on generating pdf and ipynb files, please refer to project 1 instructions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "871f2XhgtoYX"
   },
   "source": [
    "Names: Yiqing Luo, Zehua Zhang\n",
    "\n",
    "Netids: yl2546, zz727\n",
    "\n",
    "\n",
    "Don't forget to share your newly copied notebook with your partner!\n",
    "\n",
    "\n",
    "**Reminder: both of you can't work in this notebook at the same time from different computers/browser windows because of sync issues. We even suggest to close the tab with this notebook when you are not working on it so your partner doesn't get sync issues.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nISFx8ULuXMM"
   },
   "source": [
    "### Q0: Individual Member Contribution\n",
    "\n",
    "Briefly explain the contribution of individual group members here. Report if working loads are unfairly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iguUiw0mor52"
   },
   "source": [
    "# Overview\n",
    "\n",
    "---\n",
    "\n",
    "In this project, you will implement a model that identifies relevant information in a text and tags it with the appropriate label. Particularly, the task of this project is **Propaganda Identification**. The given dataset contains (manual) annotations indicating fragments of text that exhibit one of a set of well-known [propaganda techniques](https://propaganda.qcri.org/annotations/definitions.html). Your task is to develop NLP models to identify these propagandistic spans of text automatically. We will treat this as a **sequence-tagging task**: for each token in the input text, assign a label $y\\in\\{0,1\\}$, such that *1 represents propagandistic text* and *0 represents non-propaganda*.   (A description of the original task formulation is [here](https://propaganda.qcri.org/ptc/).  We are working on a modified version of their \"span identification\" task.)\n",
    "\n",
    "For this project, you will implement two sequence labeling approaches:\n",
    "\n",
    "- Model 1 : a Hidden Markov Model (HMM)\n",
    "- Model 2 : a Maximum Entropy Markov Model (MEMM), which is an adaptation of an HMM in which a Logistic Regression classifier (also known as a MaxEnt classifier) is used to obtain the lexical generation probabilities (i.e., the observation/emission probability matrix, so \"observations\" == \"emissions\" == \"lexical generations\").  Feature engineering is strongly suggested. (Papers from the [Workshops on Figurative Language Processing](https://sites.google.com/view/figlang2020/) can provide good insights on feature selection for this task.) You can also refer to the J&M book. \n",
    "\n",
    "Implementation of the Viterbi algorithm (for finding the most likely tag sequence to assign to an input text) is required for both parts, so make sure that you understand it ASAP.\n",
    "\n",
    "You will implement and train two sequence tagging models, generate your predictions for the provided test set, and submit them to **Kaggle**. Please enter all code and answer the questions of this colab notebook.\n",
    "\n",
    "**Jurafsky & Martin reading on HMMs and MEMMs can be found in Ch. 8.3–8.5.** The code you write can be added anywhere in the document, but we implore you to keep it readable. You will be asked to describe and motivate your models in parts of the document. You will be graded on both the code and text you write; see grading details at the end of the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2z7TIHV3kCH"
   },
   "source": [
    "# Notes\n",
    "\n",
    "---\n",
    "\n",
    "1. Please read through the entire notebook before you start coding. That might inform your code structure.\n",
    "2. Grading breakdown is found at the end; please consult it.\n",
    "3. Google colab does **not** provide good synchronization; we do not recommend multiple people to work on the same notebook at the same time.\n",
    "4. The project is somewhat open ended. (\"But that's a good thing.  Really. It's more fun that way\", says Claire and Esin.) We will ask you to implement some model, but precise data structures and so on can be chosen by you. However, to integrate with Kaggle, you will need to submit Kaggle predictions using our tokenization code.  As a result, **it is probably easiest if you use our tokenization code for the entire project**.\n",
    "5. You will be asked to fill in your code at various points of the document. You will also be asked to answer questions that analyze your results and motivate your implementation. These questions are named Q1-Q8. You may create additional cells to insert code, text and images as necessary.\n",
    "6. Kaggle is not able to calculate *span-level* P/R/F1 measures, which is the standard way to evaluate this type of sequence-tagging task. And we don't actually care so much about the token-level tagging accuracy, which Kaggle **can** calculate.  In particular, there are many fewer propaganda tokens than non-propaganda ones, so always guessing \"non-propaganda\" would produce a very high accuracy.  So we are compromising by using token-level **weighted accuracy**.  Here is how it works:\n",
    "\n",
    "A **weighted accuracy** metric that favors finding propagandistic tokens over non-propagandistic ones. The weights for both classes are the inverse of their frequencies.  \n",
    "\n",
    "``` \n",
    "frac_propaganda = num_propaganda/num_labels   [in the answer key]\n",
    "weight_propaganda = 1/frac_propaganda  \n",
    "weight_non_propaganda = 1/(1-frac_propaganda)\n",
    "\n",
    "weighted_accuracy = \n",
    "   ((weight_propaganda * # propaganda correct) \n",
    "                      +\n",
    "   (weight_non_propaganda * # non_propaganda correct)) / \n",
    "   \n",
    "   ((weight_propaganda * num_propaganda) \n",
    "                      +\n",
    "   (weight_non_propaganda * num_non_propaganda))\n",
    "```  \n",
    "This is also known as the **macro average**, i.e., the average of the accuracy for each label type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGG5rb9Hp6Yx"
   },
   "source": [
    "# Task and dataset\n",
    "\n",
    "---\n",
    "\n",
    "1. Obtain the data from Kaggle at https://www.kaggle.com/t/8a8030baefcc4d91b715f114353dba38.\n",
    "2. Unzip the data. Put it into your google drive, and mount it on colab as per below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "c3dQChuccqfN",
    "outputId": "23c79f72-779c-4be6-c598-33e205fddfdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "['article725731328.task-si.labels', 'article702077783.txt', 'article724095467.txt', 'article776535164.txt', 'article763761219.txt']\n",
      "['article741655444.txt', 'article755170235.txt', 'article727634031.txt', 'article769427494.txt', 'article758512204.txt']\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "\n",
    "\n",
    "train_path = os.path.join(os.getcwd(), \"drive\", \"My Drive/CS4740/project2\", \"train\") # replace based on your Google drive organization\n",
    "test_path = os.path.join(os.getcwd(), \"drive\", \"My Drive/CS4740/project2\", \"test\") # replace based on your Google drive organization\n",
    "print(os.listdir(train_path)[:5])\n",
    "print(os.listdir(test_path)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW_okuMMO9w_"
   },
   "source": [
    "3. The *train* directory contains *article{XXX}.txt* files which are plaintext documents and also *label* files such as *article{XXX}.task-si.labels*. These label files correspond to the byte-span offests of each segment of propaganda in the associated article. (The tokenizer that we describe just below converts the byte-span representation of propagandistic text spans  into the token-level gold-standard labels that your sequence-tagging models require for training.) The test directory *only* contains articles; you will use your models to detect the propagandistic spans within them.  \n",
    "\n",
    "4. We provide a tokenizer for these documents. You **must** use this tokenizer as the labels that Kaggle expects are based upon this tokenization. The code below tokenizes each document and generates the appropriate token-level labels consistent with the associated *labels* file. (This is so that you do not need to perform any byte-level text processing.  In particular, the tokenizer  merges nested or overlapping propagandistic text spans from the article into a single segment. You really shouldn't have to look at the *lables* files at all.) The code uses python type annotations; these indicate the type of arguments the functions take.\n",
    "\n",
    "5. Documents are represented as a list of strings, each being a token. Labels are represented as a list of integers in {0,1}, 1 corresponding to a propagandistic token and 0 to not propaganda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "gx5JbHlG0qmR",
    "outputId": "0f577a3b-6986-45b7-c8c6-28dadccec542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def read_txt(fname):\n",
    "  with open(fname) as open_article:\n",
    "    lines = open_article.read()\n",
    "  return lines\n",
    "\n",
    "def read_labels(labels : str) -> List[Tuple[int, int]]:\n",
    "\t\"processing of labels file\"\n",
    "\tlabels = labels.split(\"\\n\")[:-1]\n",
    "\tlabels = [tuple(map(int, l.split(\"\\t\")[1:])) for l in labels]\n",
    "\treturn labels\n",
    "\n",
    "def sort_and_merge_labels(labels : List[Tuple[int, int]]) -> List[Tuple[int, int]]:\n",
    "  \"sort labels, necessary for later splitting\"\n",
    "  if len(labels) == 0:\n",
    "    return labels\n",
    "  labels = list(sorted(labels, key = lambda t: t[0]))\n",
    "  # merge\n",
    "  curr = labels[0]\n",
    "  merged = []\n",
    "  for l in labels[1:]:\n",
    "      # if distinct, add\n",
    "      if l[0] > curr[1]:\n",
    "        merged.append(curr)\n",
    "        curr = l\n",
    "      # else merge\n",
    "      else:\n",
    "        curr = (curr[0], max(curr[1], l[1]))\n",
    "  merged.append(curr)\n",
    "  return merged\n",
    "\n",
    "def split_with_labels(labels : List[Tuple[int, int]], article : str) -> Tuple[List[str], List[int]]:\n",
    "  \"split text into segments based upon labels\"\n",
    "  if len(labels) == 0:\n",
    "    return [article], [0]\n",
    "  segments = []\n",
    "  binary_class = []\n",
    "  start = 0\n",
    "  for l_start, l_end in labels:\n",
    "    std_seg = article[start:l_start]\n",
    "    prop_seg = article[l_start:l_end]\n",
    "    segments.append(std_seg)\n",
    "    binary_class.append(0)\n",
    "    segments.append(prop_seg)\n",
    "    binary_class.append(1)\n",
    "    start = l_end\n",
    "  last_seg = article[start:]\n",
    "  segments.append(last_seg)\n",
    "  binary_class.append(0)\n",
    "  return segments, binary_class\n",
    "\n",
    "def remove_newline_fix_punc_seg(segments):\n",
    "  \" preprocessing necessry for tokenization to be consistent\"\n",
    "  segments = [s.replace(\"\\n\", \" \").replace(\".\", \" .\") for s in segments]\n",
    "  return segments\n",
    "\n",
    "def remove_newline_fix_punc_art(article):\n",
    "  \" preprocessing necessry for tokenization to be consistent\"\n",
    "  article = article.replace(\"\\n\", \" \").replace(\".\", \" .\")\n",
    "  return article\n",
    "\n",
    "def get_toks(input):\n",
    "  output = []\n",
    "  for toks in [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(input)]:\n",
    "    output += toks\n",
    "  return output\n",
    "\n",
    "# This is the function you may need to call\n",
    "def tokenize_article(article_file):\n",
    "  \"calls all functions above and perform sanity checks\"\n",
    "  article = read_txt(article_file)\n",
    "  article = remove_newline_fix_punc_art(article)\n",
    "  art_toks = get_toks(article)\n",
    "  return art_toks\n",
    "\n",
    "# This is the function you may need to call\n",
    "def master_tokenizer(article_file, labels_file):\n",
    "  \"calls all functions above and perform sanity checks\"\n",
    "\t# read and get labels\n",
    "  article = read_txt(article_file)\n",
    "  labels = read_txt(labels_file)\n",
    "  labels = read_labels(labels)\n",
    "  labels = sort_and_merge_labels(labels)\n",
    "  segments, binary_class = split_with_labels(labels, article)\n",
    "  article = remove_newline_fix_punc_art(article)\n",
    "  segments = remove_newline_fix_punc_seg(segments)\n",
    "  # sanity check\n",
    "  reconstructed = \"\"\n",
    "  for seg, lab in zip(segments, binary_class):\n",
    "    reconstructed += seg\n",
    "  assert reconstructed == article\n",
    "\t# tokenize\n",
    "  seg_toks = []\n",
    "  new_labels = []\n",
    "  for seg, label in zip(segments, binary_class):\n",
    "    new_toks = get_toks(seg)\n",
    "    seg_toks += new_toks\n",
    "    new_labels += [label for _ in range(len(new_toks))]\n",
    "\t# sanity check\n",
    "  art_toks = get_toks(article)\n",
    "  sanity = True\n",
    "  if len(art_toks) != len(seg_toks):\n",
    "    sanity = False\n",
    "  for i, (at, st, lab) in enumerate(zip(art_toks, seg_toks, new_labels)):\n",
    "    if at != st:\n",
    "      sanity = False\n",
    "      break\n",
    "  return seg_toks, new_labels, sanity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xm1CmgGQFqM"
   },
   "source": [
    " 6. Execute the commands below to visualize the tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2BsgakckQJzI",
    "outputId": "6a1070d8-e5a9-4a2f-f68c-cb70de023580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 700 ['dan', 'fishback', ':', 'it', \"'s\", 'okay', 'to', 'boycott', 'israeli', 'plays']\n"
     ]
    }
   ],
   "source": [
    "article_file = \"article698018235.txt\"\n",
    "labels_file = \"article698018235.task-si.labels\"\n",
    "article_file = os.path.join(train_path, article_file)\n",
    "labels_file = os.path.join(train_path, labels_file)\n",
    "tokens, labels, _ = master_tokenizer(article_file, labels_file)\n",
    "\n",
    "print(len(tokens), len(labels), tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQV44Fv4QrwT"
   },
   "source": [
    "7.  Provide some quantitative data exploration. Assess dataset size, documents lengths and class inbalance. Give some examples of sentences containing propaganda techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "ZPvLbjgHHnE2",
    "outputId": "389626c6-1336-4f2e-ec95-40104d218caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radical anti-israel hate group',\n",
       " 'anti-israel bds hate group',\n",
       " 'anti-semite',\n",
       " 'accused jews of drinking blood',\n",
       " \"eu no longer considers # hamas a terrorist group . time for us to do same . ''\",\n",
       " 'anti-israel',\n",
       " \"any jew who opposes the occupation — or opposes zionism itself — knows that feeling of being shunned from the places that are supposed to shelter and nurture you : families , synagogues , community centers , arts organizations , ''\",\n",
       " 'terrified',\n",
       " 'if our jewish institutions — particularly the american jewish historical society — can not accommodate dissent , and effectively exclude all jewish anti-zionists , then they have not only lost a rapidly growing jewish population , but they have lost a key aspect of their jewishness',\n",
       " 'knapsack of entitled nonsense']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examples of sentences containing propaganda techniques\n",
    "start_end=[]\n",
    "prev=0\n",
    "\n",
    "for i in range(len(labels)): #find occurances of \"1\" and record index\n",
    "  cur=labels[i]\n",
    "  if cur==1 and prev==0:\n",
    "    start=i\n",
    "  if cur==0 and prev==1:\n",
    "    end=i\n",
    "    start_end.append((start,end))\n",
    "  prev=cur\n",
    "    \n",
    "prop_example=[]\n",
    "for tups in start_end: #use the indexes in labels to find tokens and build sentences\n",
    "  start=tups[0]\n",
    "  end=tups[1]\n",
    "  sentence=\" \".join(tokens[start:end])\n",
    "  prop_example.append(sentence)\n",
    "\n",
    "prop_example[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPMHBFk3JZK-"
   },
   "outputs": [],
   "source": [
    "# Collect all the data\n",
    "article_files = [file for file in os.listdir(train_path) if file[-3:] == 'txt']\n",
    "labels_files = [file for file in os.listdir(train_path) if file[-6:] == 'labels']\n",
    "article_files.sort()\n",
    "labels_files.sort()\n",
    "print('Missing data or label' if len(article_files) != len(labels_files) else None)\n",
    "\n",
    "total_data = []\n",
    "total_labels = []\n",
    "for article_file, labels_file in zip(article_files, labels_files):\n",
    "  article_file = os.path.join(train_path, article_file)\n",
    "  labels_file = os.path.join(train_path, labels_file)\n",
    "  data, labels, sanity = master_tokenizer(article_file, labels_file)\n",
    "  if not sanity:\n",
    "    print(article_file)\n",
    "    continue\n",
    "  total_data.append(data)\n",
    "  total_labels.append(labels)\n",
    "\n",
    "# Total articles in train dataset:\n",
    "print(\"Total articles in train dataset: \", len(article_files))\n",
    "print()\n",
    "\n",
    "# Average tokens in an article: \n",
    "print(\"Average tokens in an article: \", \n",
    "   np.mean([len(file) for file in total_data]))\n",
    "print()\n",
    "\n",
    "# Count of propagandistic token and count of nonpropagandistic token: \n",
    "print(\"Count of propagandistic token: \",\n",
    "   np.sum([file.count(1) for file in total_labels]))\n",
    "print(\"Count of nonpropagandistic token: \",\n",
    "   np.sum([file.count(0) for file in total_labels]))\n",
    "print(\"Classes are imbalance: propagandistic token is far less than nonpropagandistic token\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO7go9ivDusU"
   },
   "source": [
    "### Q1: Initial data observations\n",
    "What are your initial observations of the dataset after you explore the dataset?\n",
    "\n",
    "**Answer:** There is a total of 260 articles in the training dataset. The average number of tokens in an article is 966. The count of propagandistic token is 26497 and the count of nonpropagandistic token is 224778. The classes are imbalanced since propagandistic token is far less than nonpropagandistic token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NYvfchqqBf6"
   },
   "source": [
    "# Model 1: HMM Implementation\n",
    "\n",
    "---\n",
    "\n",
    "In this section, you will implement a HMM model for this task. We expect:\n",
    "\n",
    "\n",
    "1. An implementation of the **Viterbi algorithm** that can be used to infer token-level labels --- propaganda or not propaganda --- for an input document.   This process is commonly referred to as **decoding**.\n",
    "2. Code for counting and smoothing of labels and words as necessary to support the HMM decoding. (This is pretty much what you already know how to do from project 1.)\n",
    "\n",
    "\n",
    "The tokenization of documents can be performed with the code we provide above. We suggest you calculate probabilities in a log form.  Bigram Viterbi is O(sm^2) where s is the length of the sentence and m is the number of tags. Your implementation should have similar efficiency.\n",
    "\n",
    "Code of Academic Integrity:  We encourage collaboration regarding ideas, etc. However, please **do not copy code from online or share code with other students**. We will be running programmes to detect plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLA36GdFc8RD"
   },
   "outputs": [],
   "source": [
    "# Your implementation here\n",
    "# we expect a function or class, mapping a sequence of tokens to a sequence of labels\n",
    "# this function or class will be called below\n",
    "def hmm_train(data, labels, k):\n",
    "  '''\n",
    "  Train the data to get the transition probability matrix, \n",
    "  the emission probabilities, the initial probability distribution. \n",
    "  We have already known that there are only two state: \n",
    "  propagandistic (1) and propaganda (0). \n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  label: list of list of {0, 1}\n",
    "  k: integer for add-k smoothing\n",
    "  Output:\n",
    "  tran_prob: matrix of shape (2, 2) represent log transition probability\n",
    "    tran_prob[i][j] means P(t = j|t = i)\n",
    "  emi_prob: dictionary of list represent log emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  init_prob: matrix of shape (2, ) represent log initial probability\n",
    "  unk_porb: matrix of shape (2, ) represent log unknown word emission probability\n",
    "  '''\n",
    "\n",
    "  tran_prob = np.zeros((2, 2))\n",
    "  emi_prob = {}\n",
    "  init_prob = np.zeros(2)\n",
    "  unk_prob = np.zeros(2)\n",
    "  for i in range(len(data)):\n",
    "    unk_prob[0] += labels[i].count(0)\n",
    "    unk_prob[1] += labels[i].count(1)\n",
    "    init_prob[labels[i][0]] += 1\n",
    "    if data[i][0] not in emi_prob:\n",
    "      emi_prob[data[i][0]] = [0, 0]\n",
    "    emi_prob[data[i][0]][labels[i][0]] += 1\n",
    "    for j in range(len(data[i]) - 1):\n",
    "      tran_prob[labels[i][j]][labels[i][j + 1]] += 1\n",
    "      if data[i][j] not in emi_prob:\n",
    "        emi_prob[data[i][j]] = [0, 0]\n",
    "      emi_prob[data[i][j]][labels[i][j]] += 1\n",
    "  for i in range(2):\n",
    "    tran_prob[i] = np.log(tran_prob[i] / unk_prob[i])\n",
    "\n",
    "  unk_prob += k * len(emi_prob)\n",
    "  for token in emi_prob.keys():    \n",
    "    for i in range(2):\n",
    "      emi_prob[token][i] = np.log((emi_prob[token][i] + k) / unk_prob[i])\n",
    "\n",
    "  init_prob = np.log(init_prob / len(data))\n",
    "  unk_prob = np.log(unk_prob / np.sum(unk_prob))\n",
    "  return tran_prob, emi_prob, init_prob, unk_prob\n",
    "\n",
    "def handle_oov(word):\n",
    "  if word in emi_prob:\n",
    "    return word\n",
    "  else:\n",
    "    for i in range(len(word)):\n",
    "      for w in emi_prob.keys():\n",
    "        if w.startswith(word[:-i]):\n",
    "          return w\n",
    "    return 'a'\n",
    "\n",
    "def hmm_predict(data, tran_prob, emi_prob, init_prob, unk_prob):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  tran_prob: matrix of shape (2, 2) represent transition probability\n",
    "    tran_prob[i][j] means P(t = j|t = i)\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  init_prob: matrix of shape (2, ) represent initial probability\n",
    "  unk_porb: matrix of shape (2, ) represent unknown word emission probability\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "  prediction = []\n",
    "  for tokens in data:\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    word = handle_oov(tokens[0])\n",
    "    for i in range(2):\n",
    "      score[i][0] = init_prob[i] + emi_prob[word][i]\n",
    "    for t in range(1, length):\n",
    "      word = handle_oov(tokens[t])\n",
    "      for i in range(2):\n",
    "        temp = [score[j][t - 1] + tran_prob[j][i] for j in range(2)]\n",
    "        score[i][t] = max(temp) + emi_prob[word][i]\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fwz5ja1RV7H"
   },
   "outputs": [],
   "source": [
    "#a function that takes in a 1-d list of tokens to output a 1-d list of labels for the submission generater\n",
    "def hmm(data):\n",
    "  test=[]\n",
    "  test.append(data)\n",
    "  tran_prob, emi_prob, init_prob, unk_prob = hmm_train(total_data, total_labels, 0.01)\n",
    "  hmm_prediction = hmm_predict(test, tran_prob, emi_prob, init_prob, unk_prob)\n",
    "  label_sequence=hmm_prediction[0].tolist()\n",
    "  return label_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J8NdM_V_A4u"
   },
   "source": [
    "## Validation Step\n",
    "\n",
    "1. Create a validation set from the given dataset, i.e. a subset of (~10%) the training dataset that you only use for evaluating the models, not for training.  (You can think of the validation set as a sample test set.)\n",
    "2. Train your HMM model on the (remainder of the) training set and evaluate it on the validation set. Report **weighted accuracy**, which is explained in the *Notes* section above.\n",
    "\n",
    "Please also take a look into your misclassified cases, as we will be performing error analysis in the *Evaluation* section. We expect smoothing, unknown word handling and correct emission (i.e., lexical generaion) probabilities. \n",
    "\n",
    "In the *Kaggle Submission* section, there is code provided for generating the output file in the form required for Kaggle.  If you find it useful for computing weighted accuracy, you can use it here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Lmx9z5WGAfq"
   },
   "outputs": [],
   "source": [
    "# Evaluate/validate your model here\n",
    "# you may attach pictures of graphs etc.\n",
    "\n",
    "import random\n",
    "\n",
    "def accuracy(prediction, labels):\n",
    "  '''\n",
    "  Calculate the accuracy given the prediction and ground truth\n",
    "  Input:\n",
    "  predition: list of list of {0, 1}  \n",
    "  label: list of list of {0, 1}\n",
    "  Output:\n",
    "  accuracy: float between 0 and 1\n",
    "  '''\n",
    "\n",
    "  propaganda = 0\n",
    "  propaganda_correct = 0\n",
    "  non_propaganda = 0\n",
    "  non_propaganda_correct = 0\n",
    "  for pred, label in zip(prediction, labels):\n",
    "    for p, l in zip(pred, label):\n",
    "      if l == 1:\n",
    "        propaganda += 1\n",
    "        if p == 1:\n",
    "          propaganda_correct += 1\n",
    "      else:\n",
    "        non_propaganda += 1\n",
    "        if p == 0:\n",
    "          non_propaganda_correct += 1\n",
    "  # print((propaganda_correct / propaganda), (non_propaganda_correct / non_propaganda))\n",
    "\n",
    "  return ((propaganda_correct / propaganda) + (non_propaganda_correct / non_propaganda)) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDYJwWhHVtBz"
   },
   "outputs": [],
   "source": [
    "#create training data and validation data\n",
    "total_combine = list(zip(total_data, total_labels))\n",
    "random.shuffle(total_combine)\n",
    "shuffled_data, shuffled_labels = zip(*total_combine)\n",
    "\n",
    "validation_data = shuffled_data[:26]\n",
    "validation_labels = shuffled_labels[:26]\n",
    "training_data = shuffled_data[26:]\n",
    "training_labels = shuffled_labels[26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zIDHnk5wUUJp",
    "outputId": "45c4422b-f65f-4297-f46f-afb034e10f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542016358227231\n"
     ]
    }
   ],
   "source": [
    "tran_prob, emi_prob, init_prob, unk_prob = hmm_train(training_data, training_labels, 0.01)\n",
    "hmm_prediction = hmm_predict(validation_data, tran_prob, emi_prob, init_prob, unk_prob)\n",
    "weighted_accuracy = accuracy(hmm_prediction, validation_labels)\n",
    "print(weighted_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRLi5TDyuSx_"
   },
   "source": [
    "\n",
    "\n",
    "### Q2 : Explan your HMM implementations\n",
    "\n",
    "Q2.1: Explain here how you implemented HMMs (e.g. **which algorithms/data structures** you used). Make clear which parts were implemented from scratch vs. obtained via an existing package. \n",
    "\n",
    "**Answer:** Every part of this HMM are implemented from scratch. We use matrix/list for transition probability, initial probability. We use dictionary for emission probability. Because we want to find the emission probability of a word. So we use dictionary and the keys are words. For unknown words handling, we use prefix to find the similar word in the emission probability dictionary. We also implement Viterbi algorithms from scratch. \n",
    "\n",
    "Q2.2: Explain and motivate any design choices providing the intuition behind them (e.g. which methods you used for your HMM implementation, why?).\n",
    "\n",
    "**Answer:** There are several design we use. First is Viterbi algorithms for decoding. Because we need to reduce the search complexity for decoding, we use Viterbi algorithms. We use prefix to handle unknown words. We believe similar words might have similar meanings and they are more likely to be both propagandistic of both not. And the prefix affect the meaning of a word more than suffix. So if there is an unknown word, we choose the word from the dictionary which had the longest common prefix to explain the unknown word. We also use add-k smoothing. Because we will have situations which never happened in the training, like a word have a new state. To prevent 0 in log, we use add-k smoothing. And we don't want the add-k to affect the accuracy, we did experiment for different k values and determine the k value based on accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILg8rpRAExcq"
   },
   "outputs": [],
   "source": [
    "def gen_hmm_accuracies(klist):\n",
    "  accuracies=[]\n",
    "  for i in range(len(klist)):\n",
    "    tran_prob, emi_prob, init_prob, unk_prob = hmm_train(training_data, training_labels, klist[i])\n",
    "    prediction = hmm_predict(validation_data, tran_prob, emi_prob, init_prob, unk_prob)\n",
    "    weighted_accuracy = accuracy(prediction, validation_labels)\n",
    "    accuracies.append(weighted_accuracy)\n",
    "  return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "o_q2On1fG4G2",
    "outputId": "15152bf9-ebee-40d4-946a-6a86fbb7a64a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weighted Accruacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k=1</th>\n",
       "      <td>0.499738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=0.1</th>\n",
       "      <td>0.540672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=0.01</th>\n",
       "      <td>0.554202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k=0.001</th>\n",
       "      <td>0.544219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Weighted Accruacy\n",
       "k=1               0.499738\n",
       "k=0.1             0.540672\n",
       "k=0.01            0.554202\n",
       "k=0.001           0.544219"
      ]
     },
     "execution_count": 380,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klist=[1, 0.1, 0.01, 0.001]\n",
    "accuracies=gen_hmm_accuracies(klist)\n",
    "rowname=[\"k=\"+str(klist[i]) for i in range(len(klist))]\n",
    "pd.DataFrame(accuracies,rowname,[\"Weighted Accruacy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y55T-_DfCNO5"
   },
   "outputs": [],
   "source": [
    "def accuracy_df(prediction, labels):\n",
    "  falseneg = 0\n",
    "  truepos = 0\n",
    "  falsepos = 0\n",
    "  trueneg = 0\n",
    "  for pred, label in zip(prediction, labels):\n",
    "    for p, l in zip(pred, label):\n",
    "      if l == 1 and p == 1: \n",
    "        truepos += 1\n",
    "      if l==1 and p==0:\n",
    "        falseneg+=1\n",
    "      if l==0 and p == 0:\n",
    "        trueneg += 1\n",
    "      if l==0 and p==1:\n",
    "        falsepos+=1\n",
    "  return (truepos,falseneg,trueneg,falsepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "MVBRUG4dCRBw",
    "outputId": "9ca11752-6893-4390-8340-4a213e2b03f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-propaganda</th>\n",
       "      <th>propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20313</td>\n",
       "      <td>1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non-propaganda  propaganda\n",
       "0           20313        1812\n",
       "1             716         301"
      ]
     },
     "execution_count": 381,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_true_pos,hmm_false_neg,hmm_true_neg,hmm_false_pos=accuracy_df(hmm_prediction,validation_labels)\n",
    "hmm_df=pd.DataFrame([[hmm_true_neg,hmm_false_neg], [hmm_false_pos, hmm_true_pos]],\n",
    "                   columns=['non-propaganda', 'propaganda'])\n",
    "hmm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "m1C6uBWjChxB",
    "outputId": "4455ee5b-852d-4094-e246-38b9968c2252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of propaganda correctly labeled: 0.14245149077141506\n",
      "Percentage of nonpropaganda correctly labeled: 0.9659517808740311\n"
     ]
    }
   ],
   "source": [
    "percent_true_pos=hmm_true_pos/(hmm_false_neg+hmm_true_pos)\n",
    "percent_true_neg=hmm_true_neg/(hmm_false_pos+hmm_true_neg)\n",
    "print(\"Percentage of propaganda correctly labeled:\",percent_true_pos)\n",
    "print(\"Percentage of nonpropaganda correctly labeled:\",percent_true_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "ktOTiIEy457q",
    "outputId": "f44ae645-ba46-4435-ed38-400526488187"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985237</td>\n",
       "      <td>0.013634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114419</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.985237  0.013634\n",
       "1  0.114419  0.885417"
      ]
     },
     "execution_count": 383,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transition probabilities\n",
    "transition=[0,1]\n",
    "pd.DataFrame(np.exp(tran_prob),transition,transition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHbzRuil-yjG"
   },
   "source": [
    "### Q3: Results Analysis\n",
    "\n",
    "Q3.1: Explain here how you evaluated the models. Summarize the performance of your system and any variations that you experimented with on the validation datasets. Put the results into clearly labeled tables or diagrams and include your observations and analysis. \n",
    "\n",
    "**Answer:** We evaluted the performance of the model using weighted accuracy. We used add-k smoothing in our HMM model and experimented with different k values. The above table showed that a we get highest weighted accuracy when k=0.01, so we picked it as our parameter value.\n",
    "\n",
    "\n",
    "Q3.2: When did the system work well? When did it fail?  Any ideas as to why? How might you improve the system?\n",
    "\n",
    "**Answer:** As the above table shows, our model predicts nonpropagandistic words much better than propagandistic words. A possible reason may be that, according to the table above, transition probability 0->0 is much higher than transition probability 0->1, and transition probability 1->1 is much higher than that of 1->0. When a propaganda word has previous tag=0, it is more likely to be predicted to have label 0 rather than 1, and the training data has much more nonpropagandistic words than propagandistic words. The system can be improved by taking in a larger window of tokens and tags into consideration.\n",
    "\n",
    "Q3.3: What is the effect of unknown word handling and smoothing?\n",
    "\n",
    "**Answer:** Unknown word handling deals with word in test data that has never occurred during training. Smoothing gives a non-zero probability to word-label pair that was not seen during training, to avoid log(0). Both of them increase accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31e3sMHZrLWP"
   },
   "source": [
    "# Model 2: MEMM Implementation\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this section, you will implement a Maximum Entropy Markov Model (**MEMM**) to perform the same propaganda detection task. Your model should consist of a MaxEnt classifier with Viterbi decoding. \n",
    " \n",
    "1. We have already performed tokenizations for documents. You can either use a MaxEnt classifier from an existing package or write the MaxEnt code yourself. **Important note:  MaxEnt classifiers are statistically equivalent to multi-class logistic regression, so you can use packages for multi-class LR instead of MaxEnt.**\n",
    "\n",
    "2. Use the classifier to learn a probability P(t_i|features). You may replace either the lexical generation probability – P(w_i|t_i) – or the transition probability – P(t_i|t_{i−1}) – in the HMM with it, or you may replace the entire *lexical generation probability * transition probability*  calculation – P (w_i|t_i) ∗ P (t_i|t_{i−1)} –  in the HMM with it. \n",
    "\n",
    "3. To train such classifier, you need to pick some feature set. The content of the feature set is up to your choice. You should be trying different feature sets, and evaluate your choices on the validation set. Pick the feature set that performs overall the best according to the F1 measure.\n",
    "\n",
    "4. Use your own implementation of the **Viterbi algorithm**, which you can modify from the one you developed for the HMM model. You will need the probabilities that you obtain from the MaxEnt classifier. \n",
    "\n",
    "5. Remember to use same training and validation split when evaluating the MEMM to have a **fair comparison** with your **HMM model**.\n",
    "\n",
    "\n",
    "Please also take a look into your misclassified cases, as we will be performing error analysis in *Evaluation* section. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJIosHVJZ-1o"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "Work flow summary:\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=14VfjW3yDyXLojWM_u0LeJYdDOSLkElBn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xBYPGLUHH7n"
   },
   "outputs": [],
   "source": [
    "# Your model implementation here\n",
    "# we expect a function of class, mapping a sequence of tokens to a sequence of labels\n",
    "# this function or class will be called below\n",
    "#\n",
    "# You will need:\n",
    "# 1. Extract Features\n",
    "# 2. Train MaxEnt\n",
    "# 3. To call Viterbi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FYnQP4KiG_d"
   },
   "outputs": [],
   "source": [
    "actual_labels=[]\n",
    "for article in training_labels:\n",
    "  for i in range(len(article)):\n",
    "    actual_labels.append(article[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7B13KOffb9J"
   },
   "outputs": [],
   "source": [
    "#a list of current word\n",
    "current_word=[]\n",
    "for article in training_data:\n",
    "  for i in range(len(article)):\n",
    "    current_word.append(article[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S70ktPpOgTiu"
   },
   "outputs": [],
   "source": [
    "#a list of previous tags\n",
    "previous_tag=[]\n",
    "for article in training_labels:\n",
    "  previous_tag.append(-1) #word at start of sentence has previous tag -1\n",
    "  for i in range(1,len(article)):\n",
    "    previous_tag.append(article[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcQMv98XqjhI"
   },
   "outputs": [],
   "source": [
    "#a list of part of speech tags\n",
    "training_pos=[]\n",
    "for article in training_data:\n",
    "  pos_output=nltk.pos_tag(article)\n",
    "  for tup in pos_output:\n",
    "    training_pos.append(tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQkjq7Fx5W3t"
   },
   "outputs": [],
   "source": [
    "#a list of previous words, with start token at beginning of each article\n",
    "previous_word=[]\n",
    "for article in training_data:\n",
    "  previous_word.append('<s>')\n",
    "  for i in range(1,len(article)):\n",
    "    previous_word.append(article[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgsZ49w5fOi3"
   },
   "outputs": [],
   "source": [
    "#generate feature dictionary\n",
    "word_tag_dic=[{'cur_word': word, 'prev_tag': prev_tag} for word,prev_tag in zip(current_word,previous_tag)]\n",
    "word_pos_dic=[{'cur_word': word, 'pos':pos_tag} for word,pos_tag in zip(current_word,training_pos)]\n",
    "cur_pre_word_pos_dic=[{'cur_word': word, 'pos':pos_tag, 'pre_word':pre_word} for word,pos_tag,pre_word in zip(current_word,training_pos,previous_word)]\n",
    "word_tag_pos_dic=[{'cur_word': word, 'prev_tag': prev_tag,'pos':pos_tag} for word,prev_tag,pos_tag in zip(current_word,previous_tag,training_pos)]\n",
    "all_features_dic=[{'cur_word': word, 'prev_tag': prev_tag,'pos':pos_tag,'pre_word':pre_word} for word,prev_tag,pos_tag,pre_word in zip(current_word,previous_tag,training_pos,previous_word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8hisQpjl1GP"
   },
   "outputs": [],
   "source": [
    "#generate feature set input\n",
    "def featureset(dic_list,labels):\n",
    "  featureset=[]\n",
    "  for i in range(len(labels)):\n",
    "    featureset.append((dic_list[i],str(labels[i])))\n",
    "  return featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a9Zcj8omQMD"
   },
   "outputs": [],
   "source": [
    "features_word_tag=featureset(word_tag_dic,actual_labels)\n",
    "features_word_pos=featureset(word_pos_dic,actual_labels)\n",
    "features_cur_pre_word_pos=featureset(cur_pre_word_pos_dic,actual_labels)\n",
    "features_word_tag_pos=featureset(word_tag_pos_dic,actual_labels)\n",
    "all_features=featureset(all_features_dic,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "sR4-WlEcDFsA",
    "outputId": "51f37c8f-7a7d-447d-b758-9c4f3675b709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (2 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.107\n",
      "         Final          -0.08939        0.952\n"
     ]
    }
   ],
   "source": [
    "#train classifiers\n",
    "from nltk.classify import MaxentClassifier\n",
    "classifier_word_tag = MaxentClassifier.train(features_word_tag,max_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "q_OgNvWF-bJl",
    "outputId": "8bcc53a2-5465-40e9-c117-498aaa1e3937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.107\n",
      "             2          -0.12747        0.902\n",
      "             3          -0.08899        0.974\n",
      "             4          -0.06826        0.978\n",
      "         Final          -0.05735        0.978\n"
     ]
    }
   ],
   "source": [
    "classifier_word_tag_pos = MaxentClassifier.train(features_word_tag_pos,max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "XdSwBUuKs6Ms",
    "outputId": "c4f6d9dc-4a6e-42ec-ac88-b41c325c5425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.107\n",
      "             2          -0.20996        0.893\n",
      "             3          -0.20468        0.895\n",
      "             4          -0.20030        0.901\n",
      "         Final          -0.19711        0.903\n"
     ]
    }
   ],
   "source": [
    "classifier_word_pos = MaxentClassifier.train(features_word_pos,max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "vyEiDGGQ6HHw",
    "outputId": "c99a69ff-d6d5-4631-ed30-0af770ab628c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.107\n",
      "             2          -0.21287        0.894\n",
      "             3          -0.20598        0.903\n",
      "             4          -0.20098        0.903\n",
      "         Final          -0.19755        0.903\n"
     ]
    }
   ],
   "source": [
    "classifier_cur_pre_word_pos = MaxentClassifier.train(features_cur_pre_word_pos,max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "_WjJTgwdHLpV",
    "outputId": "4ad71fce-8e47-40a0-e535-f222df79bd3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.107\n",
      "             2          -0.13944        0.902\n",
      "             3          -0.10474        0.944\n",
      "             4          -0.08167        0.977\n",
      "         Final          -0.06762        0.979\n"
     ]
    }
   ],
   "source": [
    "classifier_all = MaxentClassifier.train(all_features,max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmUnuuxvHKXM"
   },
   "outputs": [],
   "source": [
    "# Run your model on validation set\n",
    "# You will need to \n",
    "# 1. Call your function above to get a prediction result on Validation Set\n",
    "# 2. Report Metrics\n",
    "# (See if you need to modify your feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6LcbwgAYWTG"
   },
   "outputs": [],
   "source": [
    "#current word and previous tag\n",
    "def memm_predict_word_tag(data, emi_prob, classifier):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "  prediction = []\n",
    "  for tokens in data:\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    probdict=classifier.prob_classify({'word': tokens[0], 'prevtag': -1})\n",
    "    for i in range(2):\n",
    "      classifier_prob = probdict.prob(str(i))\n",
    "      score[i][0] = np.log(classifier_prob)\n",
    "    for t in range(1, length):\n",
    "      word = tokens[t]\n",
    "      for i in range(2):\n",
    "        temp = []\n",
    "        for j in range(2):\n",
    "          probdict=classifier.prob_classify({'word': tokens[t], 'prevtag': j})\n",
    "          classifier_prob = probdict.prob(str(i))\n",
    "          temp.append(score[j][t-1] + np.log(classifier_prob))\n",
    "        score[i][t] = max(temp)\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N17iYQXt-idv"
   },
   "outputs": [],
   "source": [
    "#current word, previous tag and part of speech\n",
    "def memm_predict_word_tag_pos(data, emi_prob, classifier):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "\n",
    "  #create pos list\n",
    "  pos=[]\n",
    "  for i in range(len(data)):\n",
    "    pos.append([])\n",
    "    pos_output=nltk.pos_tag(data[i])\n",
    "    for tup in pos_output:\n",
    "      pos[i].append(tup[1])\n",
    "\n",
    "  prediction = []\n",
    "  for index in range(len(data)):\n",
    "    tokens=data[index]\n",
    "    article_pos=pos[index]\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    probdict=classifier.prob_classify({'word': tokens[0], 'pos':article_pos[0],'prev_tag':-1})\n",
    "    for i in range(2):\n",
    "      classifier_prob = probdict.prob(str(i))\n",
    "      score[i][0] = np.log(classifier_prob)\n",
    "    for t in range(1, length):\n",
    "      word = tokens[t]\n",
    "      for i in range(2):\n",
    "        temp = []\n",
    "        for j in range(2):\n",
    "          probdict=classifier.prob_classify({'word': tokens[t], 'pos':article_pos[t],'prev_tag':j})\n",
    "          classifier_prob = probdict.prob(str(i))\n",
    "          temp.append(score[j][t-1] + np.log(classifier_prob))\n",
    "        score[i][t] = max(temp)\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpPyeB0itZB_"
   },
   "outputs": [],
   "source": [
    "#current word and part of speech\n",
    "def memm_predict_word_pos(data, emi_prob, classifier):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "\n",
    "  #create pos list\n",
    "  pos=[]\n",
    "  for i in range(len(data)):\n",
    "    pos.append([])\n",
    "    pos_output=nltk.pos_tag(data[i])\n",
    "    for tup in pos_output:\n",
    "      pos[i].append(tup[1])\n",
    "\n",
    "  prediction = []\n",
    "  for index in range(len(data)):\n",
    "    tokens=data[index]\n",
    "    article_pos=pos[index]\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    probdict=classifier.prob_classify({'word': tokens[0], 'pos':article_pos[0]})\n",
    "    for i in range(2):\n",
    "      classifier_prob = probdict.prob(str(i))\n",
    "      score[i][0] = np.log(classifier_prob)\n",
    "    for t in range(1, length):\n",
    "      word = tokens[t]\n",
    "      for i in range(2):\n",
    "        temp = []\n",
    "        for j in range(2):\n",
    "          probdict=classifier.prob_classify({'word': tokens[t], 'pos':article_pos[t]})\n",
    "          classifier_prob = probdict.prob(str(i))\n",
    "          temp.append(score[j][t-1] + np.log(classifier_prob))\n",
    "        score[i][t] = max(temp)\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1TBCMg76NzJ"
   },
   "outputs": [],
   "source": [
    "#current word, previous word and part speech\n",
    "def memm_predict_cur_pre_word_pos(data, emi_prob, classifier):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "\n",
    "  #create pos list\n",
    "  pos=[]\n",
    "  for i in range(len(data)):\n",
    "    pos.append([])\n",
    "    pos_output=nltk.pos_tag(data[i])\n",
    "    for tup in pos_output:\n",
    "      pos[i].append(tup[1])\n",
    "\n",
    "  prediction = []\n",
    "  for index in range(len(data)):\n",
    "    tokens=data[index]\n",
    "    article_pos=pos[index]\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    probdict=classifier.prob_classify({'word': tokens[0], 'pos':article_pos[0],'pre_word':'<s>'})\n",
    "    for i in range(2):\n",
    "      classifier_prob = probdict.prob(str(i))\n",
    "      score[i][0] = np.log(classifier_prob)\n",
    "    for t in range(1, length):\n",
    "      word = tokens[t]\n",
    "      for i in range(2):\n",
    "        temp = []\n",
    "        for j in range(2):\n",
    "          probdict=classifier.prob_classify({'word': tokens[t], 'pos':article_pos[t],'pre_word':tokens[t-1]})\n",
    "          classifier_prob = probdict.prob(str(i))\n",
    "          temp.append(score[j][t-1] + np.log(classifier_prob))\n",
    "        score[i][t] = max(temp)\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "438Oi686HToM"
   },
   "outputs": [],
   "source": [
    "#current word, previous word and part speech\n",
    "def memm_predict_all(data, emi_prob, classifier):\n",
    "  '''\n",
    "  Predict the labels of data according to the training result\n",
    "  Input:\n",
    "  data: list of list of tokens\n",
    "  emi_prob: dictionary of list represent emission probability\n",
    "    emi_prob[token][i] means P(w = token| t = i)\n",
    "  Output:\n",
    "  label: list of list of {0, 1}\n",
    "  '''\n",
    "\n",
    "  #create pos list\n",
    "  pos=[]\n",
    "  for i in range(len(data)):\n",
    "    pos.append([])\n",
    "    pos_output=nltk.pos_tag(data[i])\n",
    "    for tup in pos_output:\n",
    "      pos[i].append(tup[1])\n",
    "\n",
    "  prediction = []\n",
    "  for index in range(len(data)):\n",
    "    tokens=data[index]\n",
    "    article_pos=pos[index]\n",
    "    length = len(tokens)\n",
    "    score = np.zeros((2, length))\n",
    "    bptr = np.zeros((2, length))\n",
    "    probdict=classifier.prob_classify({'word': tokens[0], 'pos':article_pos[0],'pre_word':'<s>','pre_tag':-1})\n",
    "    for i in range(2):\n",
    "      classifier_prob = probdict.prob(str(i))\n",
    "      score[i][0] = np.log(classifier_prob)\n",
    "    for t in range(1, length):\n",
    "      word = tokens[t]\n",
    "      for i in range(2):\n",
    "        temp = []\n",
    "        for j in range(2):\n",
    "          probdict=classifier.prob_classify({'word': tokens[t], 'pos':article_pos[t],'pre_word':tokens[t-1],'pre_tag':j})\n",
    "          classifier_prob = probdict.prob(str(i))\n",
    "          temp.append(score[j][t-1] + np.log(classifier_prob))\n",
    "        score[i][t] = max(temp)\n",
    "        bptr[i][t] = np.argmax(temp)\n",
    "    T = np.zeros(length).astype(int)\n",
    "    T[-1] = np.argmax(score[:, -1])\n",
    "    for i in range(length - 2, -1, -1):\n",
    "      T[i] = bptr[T[i + 1]][i + 1]\n",
    "    prediction.append(T)\n",
    "  \n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Oq453TPta1wI",
    "outputId": "debd0be0-ff2f-4729-9fce-45212746388e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 364,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word and previous tag\n",
    "memm_prediction_word_tag=memm_predict_word_tag(validation_data,emi_prob,classifier_word_tag)\n",
    "weighted_accuracy = accuracy(memm_prediction_word_tag, validation_labels)\n",
    "weighted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "jJYgvq5XZZfg",
    "outputId": "3251471a-3f2d-4681-8dc6-6c82eb381684"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-propaganda</th>\n",
       "      <th>propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21029</td>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non-propaganda  propaganda\n",
       "0           21029        2113\n",
       "1               0           0"
      ]
     },
     "execution_count": 365,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word and previous tag\n",
    "memm_true_pos,memm_false_neg,memm_true_neg,memm_false_pos=accuracy_df(memm_prediction_word_tag,validation_labels)\n",
    "memm_df=pd.DataFrame([[memm_true_neg,memm_false_neg], [memm_false_pos, memm_true_pos]],\n",
    "                   columns=['non-propaganda', 'propaganda'])\n",
    "memm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sUDyKLra_Nrq",
    "outputId": "97085511-5a49-4d09-fe83-f6954b9078c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 366,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word, previous tag and part of speech\n",
    "memm_prediction_word_tag_pos=memm_predict_word_tag_pos(validation_data,emi_prob,classifier_word_tag_pos)\n",
    "weighted_accuracy_wtp = accuracy(memm_prediction_word_tag_pos, validation_labels)\n",
    "weighted_accuracy_wtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WNP_hzfhv3hw",
    "outputId": "9039cbc4-73c7-4110-a190-34149756db58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 367,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word and part of speech\n",
    "memm_prediction2=memm_predict_word_pos(validation_data,emi_prob,classifier_word_pos)\n",
    "weighted_accuracy2 = accuracy(memm_prediction2, validation_labels)\n",
    "weighted_accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "hphVMy8f3NYN",
    "outputId": "a4b21443-4288-4bb4-fc87-e2f57de61754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-propaganda</th>\n",
       "      <th>propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21029</td>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non-propaganda  propaganda\n",
       "0           21029        2113\n",
       "1               0           0"
      ]
     },
     "execution_count": 368,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word and part of speech matrix\n",
    "memm_true_pos,memm_false_neg,memm_true_neg,memm_false_pos=accuracy_df(memm_prediction2,validation_labels)\n",
    "memm_df=pd.DataFrame([[memm_true_neg,memm_false_neg], [memm_false_pos, memm_true_pos]],\n",
    "                   columns=['non-propaganda', 'propaganda'])\n",
    "memm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ADl6Ex3D6vxH",
    "outputId": "979d70ca-6776-41d5-e90f-86e810fd6523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5027138620934465"
      ]
     },
     "execution_count": 369,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word, previous word and part of speech\n",
    "memm_prediction3=memm_predict_cur_pre_word_pos(validation_data,emi_prob,classifier_cur_pre_word_pos)\n",
    "weighted_accuracy3 = accuracy(memm_prediction3, validation_labels)\n",
    "weighted_accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "9NqlSv7i7daF",
    "outputId": "55fe4d4d-9984-43f7-a6b4-91682223586b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-propaganda</th>\n",
       "      <th>propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20964</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non-propaganda  propaganda\n",
       "0           20964        2095\n",
       "1              65          18"
      ]
     },
     "execution_count": 370,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word, previous word and part of speech\n",
    "memm_true_pos,memm_false_neg,memm_true_neg,memm_false_pos=accuracy_df(memm_prediction3,validation_labels)\n",
    "memm_df=pd.DataFrame([[memm_true_neg,memm_false_neg], [memm_false_pos, memm_true_pos]],\n",
    "                   columns=['non-propaganda', 'propaganda'])\n",
    "memm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EkYGfIUZHyVx",
    "outputId": "4e16d600-db13-4b16-e04d-634af52a4bef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5084824155009882"
      ]
     },
     "execution_count": 371,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word, previous word, previous tag and part of speech\n",
    "memm_prediction_all=memm_predict_all(validation_data,emi_prob,classifier_all)\n",
    "weighted_accuracy_all = accuracy(memm_prediction_all, validation_labels)\n",
    "weighted_accuracy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "vouI6gw-IFAY",
    "outputId": "77406e92-3432-4dd5-9d52-4cad113ac2ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-propaganda</th>\n",
       "      <th>propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20918</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non-propaganda  propaganda\n",
       "0           20918        2066\n",
       "1             111          47"
      ]
     },
     "execution_count": 372,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current word, previous word, previous tag and part of speech\n",
    "memm_true_pos,memm_false_neg,memm_true_neg,memm_false_pos=accuracy_df(memm_prediction_all,validation_labels)\n",
    "memm_df=pd.DataFrame([[memm_true_neg,memm_false_neg], [memm_false_pos, memm_true_pos]],\n",
    "                   columns=['non-propaganda', 'propaganda'])\n",
    "memm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "iu3LbGbHUiUX",
    "outputId": "82fa9264-dfbc-4c2f-a91d-31a3a7cf68f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of propaganda correctly labeled: 0.022243256034074774\n",
      "Percentage of nonpropaganda correctly labeled: 0.9769366113462361\n"
     ]
    }
   ],
   "source": [
    "memm_percent_true_pos=memm_true_pos/(memm_false_neg+memm_true_pos)\n",
    "memm_percent_true_neg=hmm_true_neg/(memm_false_pos+memm_true_neg)\n",
    "print(\"Percentage of propaganda correctly labeled:\",memm_percent_true_pos)\n",
    "print(\"Percentage of nonpropaganda correctly labeled:\",memm_percent_true_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l63VvScqA_ru"
   },
   "outputs": [],
   "source": [
    "#a function that takes in a 1-d list of tokens to output a 1-d list of labels for the submission generater\n",
    "def memm(data):\n",
    "  test=[]\n",
    "  test.append(data)\n",
    "  tran_prob, emi_prob, init_prob, unk_prob = hmm_train(total_data, total_labels, 0.01)\n",
    "  memm_prediction = memm_predict_all(test, emi_prob, classifier_all)\n",
    "  label_sequence=memm_prediction[0].tolist()\n",
    "  return label_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGkhL1imxpmH"
   },
   "source": [
    "### Q4: Implementation Details\n",
    "\n",
    "Q4.1: Explain here how you implemented the MEMM (e.g. which algorithms/data structures you used, what features are included). Make clear which parts were implemented from scratch vs. obtained via an existing package. \n",
    "\n",
    "\n",
    "**Answer:** We used the nltk MaxEnt classifier that takes in different features and produces probability of the token having tag '0' or tag '1'. We then used the probability produced by the classifier to replace (emission probability * transition probability) in HMM, and adpated the Viterbi function in HMM.\n",
    "\n",
    "Q4.2: What features are considered most important by your MaxEnt Classifier? Why do you think these features make sense? Describe your experiments with feature sets.\n",
    "\n",
    "**Answer:** A combination of current word, previous word, previous tag and part of speech performed the best. It makes sense because this combination provides more context of a word and its function in the sentence. We have experimented with: \n",
    "\n",
    "current word + previous tag\n",
    "\n",
    "current word + previous tag + part of speech\n",
    "\n",
    "current word + part of speech\n",
    "\n",
    "current word + previous word + part of speech\n",
    "\n",
    "current word + previous word + part of speech + previous tag\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_eDwiILvHGL"
   },
   "source": [
    "### Q5: Results Analysis\n",
    "\n",
    "Q5.1: Explain here how you evaluated the MEMM model. Summarize the performance of your system and any variations that you experimented with the validation datasets. Put the results into clearly labeled tables or diagrams and include your observations and analysis. \n",
    "\n",
    "**Answer:** We used different featuresets to train the MaxEnt classifier and applied it to predict labels of the same validation set. We evaluted the performances of different feature sets by calculating the weighted accuracy.\n",
    "\n",
    "![accuracies](https://drive.google.com/uc?id=1kneTKUwXSwyNb0Kqam8MfXMJ7m4nvZUB)\n",
    "\n",
    "Q5.2: An analysis on feature selection for the MEMM is required – e.g. what features **help most**, why? An **error analysis** is required – e.g. what sorts of errors occurred, why? \n",
    "\n",
    "**Answer:** As the table shows, the first three featuresets have a weighted accuracy of 0.5, and we found that the predictor tagged every token to be nonpropaganda/0. When we added the previous word feature, the predictor started to assign propaganda/1 tags. When we added all 4 features together we reached highest weighted accuracy. It implies that previous word is the most helpful feature, and its combination with part of speech and previous tag made these features more informational than when they are by themselves.\n",
    "\n",
    "The main error of our MEMM model is that it is prone to assign 0 tags, which may be caused by the fact that 0 tags appear much more often than 1 tags, which makes the classifer more likely to assign 0 tags over 1.\n",
    "\n",
    "Q5.3: When did the system work well, when did it fail and any ideas as to why? How might you improve the system?\n",
    "\n",
    "**Answer:** The system has high accuracy in identifying nonpropagandistic words, but fails to identify propagandistic words. One way to improve the system is adding more features to capture more precise context of a given word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQwPwqU3vMiS"
   },
   "source": [
    "\n",
    "#Comparing HMMs and MEMMs\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Q6:\n",
    "\n",
    "\n",
    "Compare here your results for your HMM and the MEMM. Which of them performs better? \n",
    "\n",
    "**Answer:** From the accuracy we can find that HMM perform better. Because the Label Bias Problem, MEMM are less likely to transform the state. Because the propagandistic words are more distributed as a span of words, so the transfrom of state are very uncommon in the training data. MEMM are more likely to predict all 0s because of the Label Bias Problem and the accuracy are worse than HMM. \n",
    "\n",
    "\n",
    "###Q7: Error Analysis\n",
    "Q7.1: Do some error analysis. What are error patterns you observed that the HMM makes but the MEMM does not? Try to justify why/why not?\n",
    "\n",
    "**Answer:** Based on the example of HMM and MEMM, we can find that because of the transition probility and the propagandistic words ususally are distributed as a span of words. HMM are more likely to predict consecutive words as propagandistic words. We use capitalize to indicate propagandistic words. Such as in ground truth, <br>**BOTCHED INVESTIGATION is a stunning indictment of the fbi**.<br> And in HMM, <br>**BOTCHED INVESTIGATION IS A STUNNING INDICTMENT OF THE FBI**.<br> And in MEMM, <br>**botched INVESTIGATION is a stunning INDICTMENT of the fbi**.<br> We can see that HMM are predict the whole sentence as propagandistic and MEMM only predict few words. \n",
    "\n",
    "Q7.2: What are error patterns you observed that MEMM makes but the HMM does not? Try to justify what you observe?\n",
    "\n",
    "**Answer:** Generally speaking, HMM are more likely to predict as propagandistic and MEMM are not. So most of errors are occur in MEMM and not in HMM. This might because we use add-k smoothing in HMM and it will more likely to classify a word to propagandistic and MEMM are not. Another reason is because of Label Bias Problem, MEMM are more likely to stay on state 0. Such as in ground truth <br>**LOCAL AND FEDERAL AUTHORITIES ARE REFUSING TO FILL IN THE BLANKS**<br> In HMM, <br>**LOCAL AND FEDERAL AUTHORITIES ARE REFUSING TO FILL IN THE BLANKS**<br> And in MEMM <br> **local and federal authorities are refusing to fill in the blanks**<br> The whole scentence are missing because MEMM are more likely to stay on state 0, which is non-propagandistic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "Hix1Yy5XhTFc",
    "outputId": "e61c1672-1cb6-4cc9-92dd-515c5510a4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All propagandistic words are capitalized\n",
      "Use one article from validation set as example\n",
      "Ground Truth\n",
      "local police & feds impose information blackout in las vegas shooting there already was a blackout on the worst mass murder in modern american history . 58 dead , hundreds wounded , the savagery of the vegas attack is unspeakable , and STILL THE INCOMPETENT , CLUELESS AUTHORITIES KNOW NOTHING . THAT ’ S THE INFORMATION THEY SEEK TO BLACKOUT . this BOTCHED INVESTIGATION is a stunning indictment of the fbi . THIS IS NOT THE SOVIET UNION , THIS IS NOT IRAN OR RIYADH – THIS IS AMERICA . where is the outrage ? and while the BUMBLING FBI has dismissed out of hand jihad as a motive , here is what we know : isis has claimed responsibility for the vegas slaughter . isis does not claim credit for events that are not theirs . they have double and tripled down on their claim . they have said that stephen paddock had converted to islam six months ago , and they revealed his islamic name as abu abd abdulbar al ameriki . paddock made multiple trips to the middle east . the fbi has not spoken of his itinerary or who he met with . his girlfriend mari danley had relatives in dubai . over 200 of paddock ’ s foreign financial transactions were flagged for possible covert terrorism financing . paddock transferred $ 100,000 to his girlfriend in the philippines , now an isis foothold . paddock removed the hard drive before he committed suicide . the san bernardino jihad attackers did the same thing . if you recall , syed rizwan farook and tashfeen malik threw their hard drives in a lake near their home , and despite herculean efforts by law enforcement , the hard drives were never recovered . authorities put brakes on information flow in las vegas shooting by rachel crosby las vegas review-journal , october 26 , 2017 : fifty-eight people killed . more than 500 injured . and yet , nearly a month after the las vegas strip experienced the worst mass shooting in modern american history , LOCAL AND FEDERAL AUTHORITIES ARE REFUSING TO FILL IN THE BLANKS . it wasn ’ t always like this . in the days after oct . 1 , when stephen paddock opened fire on the route 91 harvest festival crowd from his mandalay bay corner suite , las vegas police were hosting multiple news conferences a day . then , once a day . then , once every few days . they compiled and released snippets of officers ’ body camera footage . they spent several minutes answering specific questions . they released a comprehensive timeline , which ended up being wrong . they took it back , and tried to clarify the errors , but instead caused more confusion . by oct . 13 — the last time the metropolitan police department or the fbi addressed the media or public — something had changed . the sheriff , who had been straightforward and stern , was now emotional and at times combative . both he and the fbi failed to provide much new information , and at the end of the meeting , they refused to take questions . since that day , the only person who has shed more light on the investigation is mandalay bay security guard jesus campos , who was shot in the leg while approaching the gunman ’ s room . his platform to share that information ? “ the ellen degeneres show , ” which aired last week . he hasn ’ t made himself available to the media since . “ it doesn ’ t matter , ” fbi spokeswoman sandra breault told the las vegas review-journal on thursday , when asked why there had been no significant updates in two weeks . “ it ’ s an ongoing investigation , and unless there ’ s something to report , there will not be a briefing . ” calls to the national fbi office were forwarded back to breault at the las vegas office . at least twice this week , the las vegas review-journal has asked to speak with sheriff joe lombardo about the shooting investigation . both times , reporters were told by carla alston , the police department ’ s director of communications , that the sheriff “ will not be conducting interviews . ” “ as he has stated previously , the case is still ongoing ” she said in an email thursday . “ another media briefing will be held when we have new and accurate information . ” when asked when that briefing would be , alston guessed it could occur in the next two weeks . the review-journal also specifically asked about the more than 50,000 hours of overtime that metro officers have logged since oct . 1 on work directly related to the shooting investigation . “ investigators have made progress on investigative leads and in mapping out stephen paddock ’ s life for the last few years — and they ’ re still not done , ” alston said . “ we still have officers dedicated to this case 24/7 . ” she agreed that members of the public have a right to know more , “ but they have a right to accurate information and not the speculation … that has filled so many news stories the past month . ” nearly a month after the mass shooting , the gunman ’ s motive remains a mystery . more straightforward questions also remain unanswered , including whether the 32nd floor of mandalay bay — where the gunman was staying — has surveillance cameras , and what exactly investigators collected in the gunman ’ s hotel room and homes . authorities also have not said how long the gunman had a “ do not disturb ” sign on his hotel door , and whether hotel staff saw something suspicious in his room but failed to report it . though authorities have described the investigation as a team effort , they have not explained what role las vegas police , the fbi and the bureau of alcohol , tobacco , firearms and explosives are playing in the case . article posted with permission from pamela geller . pamela geller 's commitment to freedom from jihad and shariah shines forth in her books \n",
      "\n",
      "HMM prediction\n",
      "local police & feds impose information blackout in las vegas shooting there already was a blackout on the worst mass murder in modern american history . 58 dead , hundreds wounded , the savagery of the vegas attack is unspeakable , and still the INCOMPETENT , CLUELESS AUTHORITIES KNOW NOTHING . THAT ’ S THE INFORMATION THEY SEEK TO BLACKOUT . THIS BOTCHED INVESTIGATION IS A STUNNING INDICTMENT OF THE FBI . THIS IS NOT THE SOVIET UNION , THIS IS NOT IRAN OR RIYADH – THIS IS AMERICA . WHERE IS THE OUTRAGE ? AND WHILE THE BUMBLING fbi has dismissed out of hand jihad as a motive , here is what we know : isis has claimed responsibility for the vegas slaughter . isis does not claim credit for events that are not theirs . they have double and tripled down on their claim . they have said that stephen paddock had converted to islam six months ago , and they revealed his islamic name as abu abd abdulbar al ameriki . paddock made multiple trips to the middle east . the fbi has not spoken of his itinerary or who he met with . his girlfriend mari danley had relatives in dubai . over 200 of paddock ’ s foreign financial transactions were flagged for possible covert terrorism financing . paddock transferred $ 100,000 to his girlfriend in the philippines , now an isis foothold . paddock removed the hard drive before he committed suicide . the san bernardino jihad attackers did the same thing . if you recall , syed rizwan farook and tashfeen malik threw their hard drives in a lake near their home , and despite herculean efforts by law enforcement , the hard drives were never recovered . authorities put brakes on information flow in las vegas shooting by rachel crosby las vegas review-journal , october 26 , 2017 : fifty-eight people killed . more than 500 injured . and yet , nearly a month after the las vegas strip EXPERIENCED THE WORST MASS SHOOTING IN MODERN AMERICAN HISTORY , LOCAL AND FEDERAL AUTHORITIES ARE REFUSING TO FILL IN THE BLANKS . it wasn ’ t always like this . in the days after oct . 1 , when stephen paddock opened fire on the route 91 harvest festival crowd from his mandalay bay corner suite , las vegas police were hosting multiple news conferences a day . then , once a day . then , once every few days . they compiled and released snippets of officers ’ body camera footage . they spent several minutes answering specific questions . they released a comprehensive timeline , which ended up being wrong . they took it back , and tried to clarify the errors , but instead caused more confusion . by oct . 13 — the last time the metropolitan police department or the fbi addressed the media or public — something had changed . the sheriff , who had been straightforward and stern , was now emotional and at times combative . both he and the fbi failed to provide much new information , and at the end of the meeting , they refused to take questions . since that day , the only person who has shed more light on the investigation is mandalay bay security guard jesus campos , who was shot in the leg while approaching the gunman ’ s room . his platform to share that information ? “ the ellen degeneres show , ” which aired last week . he hasn ’ t made himself available to the media since . “ it doesn ’ t matter , ” fbi spokeswoman sandra breault told the las vegas review-journal on thursday , when asked why there had been no significant updates in two weeks . “ it ’ s an ongoing investigation , and unless there ’ s something to report , there will not be a briefing . ” calls to the national fbi office were forwarded back to breault at the las vegas office . at least twice this week , the las vegas review-journal has asked to speak with sheriff joe lombardo about the shooting investigation . both times , reporters were told by carla alston , the police department ’ s director of communications , that the sheriff “ will not be conducting interviews . ” “ as he has stated previously , the case is still ongoing ” she said in an email thursday . “ another media briefing will be held when we have new and accurate information . ” when asked when that briefing would be , alston guessed it could occur in the next two weeks . the review-journal also specifically asked about the more than 50,000 hours of overtime that metro officers have logged since oct . 1 on work directly related to the shooting investigation . “ investigators have made progress on investigative leads and in mapping out stephen paddock ’ s life for the last few years — and they ’ re still not done , ” alston said . “ we still have officers dedicated to this case 24/7 . ” she agreed that members of the public have a right to know more , “ but they have a right to accurate information and not the speculation … that has filled so many news stories the past month . ” nearly a month after the mass shooting , the gunman ’ s motive remains a mystery . more straightforward questions also remain unanswered , including whether the 32nd floor of mandalay bay — where the gunman was staying — has surveillance cameras , and what exactly investigators collected in the gunman ’ s hotel room and homes . authorities also have not said how long the gunman had a “ do not disturb ” sign on his hotel door , and whether hotel staff saw something suspicious in his room but failed to report it . though authorities have described the investigation as a team effort , they have not explained what role las vegas police , the fbi and the bureau of alcohol , tobacco , firearms and explosives are playing in the case . article posted with permission from pamela geller . pamela geller 's COMMITMENT TO FREEDOM FROM JIHAD AND SHARIAH SHINES FORTH IN HER BOOKS \n",
      "\n",
      "MEMM prediction\n",
      "local police & feds impose information blackout in las vegas shooting there already was a blackout on the worst mass murder in modern american history . 58 dead , hundreds wounded , the savagery of the vegas attack is unspeakable , and still the incompetent , clueless authorities know nothing . that ’ s the information they seek to blackout . this botched INVESTIGATION is a stunning INDICTMENT of the fbi . this is not the soviet union , this is not iran or riyadh – this is america . where is the outrage ? and while the bumbling FBI has dismissed out of hand jihad as a motive , here is what we know : isis has claimed responsibility for the vegas slaughter . isis does not claim credit for events that are not theirs . they have double and tripled down on their claim . they have said that stephen paddock had converted to islam six months ago , and they revealed his islamic name as abu abd abdulbar al ameriki . paddock made multiple trips to the middle east . the fbi has not spoken of his itinerary or who he met with . his girlfriend mari danley had relatives in dubai . over 200 of paddock ’ s foreign financial transactions were flagged for possible covert terrorism financing . paddock transferred $ 100,000 to his girlfriend in the philippines , now an isis foothold . paddock removed the hard drive before he committed suicide . the san bernardino jihad attackers did the same thing . if you recall , syed rizwan farook and tashfeen malik threw their hard drives in a lake near their home , and despite herculean efforts by law enforcement , the hard drives were never recovered . authorities put brakes on information flow in las vegas shooting by rachel crosby las vegas review-journal , october 26 , 2017 : fifty-eight people killed . more than 500 injured . and yet , nearly a month after the las vegas strip experienced the worst mass shooting in modern american history , local and federal authorities are refusing to fill in the blanks . it wasn ’ t always like this . in the days after oct . 1 , when stephen paddock opened fire on the route 91 harvest festival crowd from his mandalay bay corner suite , las vegas police were hosting multiple news conferences a day . then , once a day . then , once every few days . they compiled and released snippets of officers ’ body camera footage . they spent several minutes answering specific questions . they released a comprehensive timeline , which ended up being wrong . they took it back , and tried to clarify the errors , but instead caused more confusion . by oct . 13 — the last time the metropolitan police department or the fbi addressed the media or public — something had changed . the sheriff , who had been straightforward and stern , was now emotional and at times combative . both he and the fbi failed to provide much new information , and at the end of the meeting , they refused to take questions . since that day , the only person who has shed more light on the investigation is mandalay bay security guard jesus campos , who was shot in the leg while approaching the gunman ’ s room . his platform to share that information ? “ the ellen degeneres show , ” which aired last week . he hasn ’ t made himself available to the media since . “ it doesn ’ t matter , ” fbi spokeswoman sandra breault told the las vegas review-journal on thursday , when asked why there had been no significant updates in two weeks . “ it ’ s an ongoing investigation , and unless there ’ s something to report , there will not be a briefing . ” calls to the national fbi office were forwarded back to breault at the las vegas office . at least twice this week , the las vegas review-journal has asked to speak with sheriff joe lombardo about the shooting investigation . both times , reporters were told by carla alston , the police department ’ s director of communications , that the sheriff “ will not be conducting interviews . ” “ as he has stated previously , the case is still ongoing ” she said in an email thursday . “ another media briefing will be held when we have new and accurate information . ” when asked when that briefing would be , alston guessed it could occur in the next two weeks . the review-journal also specifically asked about the more than 50,000 hours of overtime that metro officers have logged since oct . 1 on work directly related to the shooting investigation . “ investigators have made progress on investigative leads and in mapping out stephen paddock ’ s life for the last few years — and they ’ re still not done , ” alston said . “ we still have officers dedicated to this case 24/7 . ” she agreed that members of the public have a right to know more , “ but they have a right to accurate information and not the speculation … that has filled so many news stories the past month . ” nearly a month after the mass shooting , the gunman ’ s motive remains a mystery . more straightforward questions also remain unanswered , including whether the 32nd floor of mandalay bay — where the gunman was staying — has surveillance cameras , and what exactly investigators collected in the gunman ’ s hotel room and homes . authorities also have not said how long the gunman had a “ do not disturb ” sign on his hotel door , and whether hotel staff saw something suspicious in his room but failed to report it . though authorities have described the investigation as a team effort , they have not explained what role las vegas police , the fbi and the bureau of alcohol , tobacco , firearms and explosives are playing in the case . article posted with permission from pamela geller . pamela geller 's commitment to freedom from jihad and shariah shines FORTH in her books \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"All propagandistic words are capitalized\")\n",
    "print(\"Use one article from validation set as example\")\n",
    "example = 4\n",
    "single_data = validation_data[example]\n",
    "print(\"Ground Truth\")\n",
    "single_label = validation_labels[example]\n",
    "article = ''\n",
    "for i in range(len(single_data)):\n",
    "  word = single_data[i]\n",
    "  if single_label[i]:\n",
    "    word = word.upper()\n",
    "  article += word + ' '\n",
    "print(article)\n",
    "print()\n",
    "\n",
    "print(\"HMM prediction\")\n",
    "single_label = hmm_prediction[example]\n",
    "article = ''\n",
    "for i in range(len(single_data)):\n",
    "  word = single_data[i]\n",
    "  if single_label[i]:\n",
    "    word = word.upper()\n",
    "  article += word + ' '\n",
    "print(article)\n",
    "print()\n",
    "\n",
    "print(\"MEMM prediction\")\n",
    "single_label = memm_prediction_all[example]\n",
    "article = ''\n",
    "for i in range(len(single_data)):\n",
    "  word = single_data[i]\n",
    "  if single_label[i]:\n",
    "    word = word.upper()\n",
    "  article += word + ' '\n",
    "print(article)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpugxBD7RBy1"
   },
   "source": [
    "# Kaggle Submission \n",
    "---\n",
    "\n",
    "Using the best-performing system from among all of your HMM and MEMM models, generate predictions for the test set, and submit them to Kaggle at https://www.kaggle.com/t/8a8030baefcc4d91b715f114353dba38. Note, you **need** to use our tokenizer as the labels on Kaggle corresponds to these. Below, we provide a script that submits a random guess/all ones or all zeroes in the correct format. Note that you only need to provide a function which takes as input a sequence of tokens, and outputs a sequence of labels (in the form of integers  in {0,1}, 1 corresponding to propaganda). As a scoring metric on Kaggle, we use **weighted accuracy**, described in the *Notes* section towards the beginning of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUekWsLbU6rs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def submission_to_csv(binary_class : List[List[int]], fname : str):\n",
    "  # writes submission to CSV\n",
    "  new_binary = []\n",
    "  for classes in binary_class:\n",
    "    new_binary += classes\n",
    "  with open(fname, 'w') as file:\n",
    "    file.write('id,category\\n')\n",
    "    for i, line in enumerate(new_binary):\n",
    "      file.write('{},{}\\n'.format(i,line))\n",
    "\n",
    "\n",
    "def random_predictor(article_tokens : List[str]) -> List[int]:\n",
    "  # random predictor\n",
    "  output = []\n",
    "  for _ in range(len(article_tokens)):\n",
    "    output.append(random.randint(0,1))\n",
    "  return output\n",
    "\n",
    "def always_one(article_tokens : List[str]) -> List[int]:\n",
    "  # random predictor\n",
    "  output = []\n",
    "  for _ in range(len(article_tokens)):\n",
    "    output.append(1)\n",
    "  return output\n",
    "\n",
    "def always_zero(article_tokens : List[str]) -> List[int]:\n",
    "  # random predictor\n",
    "  output = []\n",
    "  for _ in range(len(article_tokens)):\n",
    "    output.append(0)\n",
    "  return output\n",
    "\n",
    "\n",
    "def generate_submission(predictor: Callable[[List[str]], List[int]], fname : str, test_path : str):\n",
    "  # generate a submission with random guesses\n",
    "  sample_submission = []\n",
    "  articles = os.listdir(test_path)\n",
    "  total, fail, targets, test_articles = 0,0, [], []\n",
    "  for article in sorted(articles):\n",
    "    article_file = os.path.join(test_path, article)\n",
    "    art_toks = tokenize_article(article_file)\n",
    "    curr_article = predictor(art_toks)\n",
    "    sample_submission.append(curr_article)\n",
    "  submission_to_csv(sample_submission, fname)\n",
    "\n",
    "\n",
    "test_path=os.path.join(os.getcwd(), \"drive\", \"My Drive/CS4740/project2\",\"test\")\n",
    "generate_submission(random_predictor, \"random_submission.csv\", test_path)\n",
    "generate_submission(always_one, \"ones_submission.csv\", test_path)\n",
    "generate_submission(always_zero, \"zeros_submission.csv\", test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeH8eEfPQQ0f"
   },
   "outputs": [],
   "source": [
    "generate_submission(hmm, \"hmm_submission2.csv\", test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgQ52r6VJ1AR"
   },
   "outputs": [],
   "source": [
    "generate_submission(memm, \"memm_submission3.csv\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jSimlgOeeXh"
   },
   "source": [
    "---\n",
    "### Q8: Competition Score\n",
    "\n",
    "Include here your **team name** and the **screenshot** of your best score from Kaggle.\n",
    "\n",
    "**Answer:** team name: yl2546_zz727\n",
    "\n",
    "![kaggle](https://drive.google.com/uc?id=1RrGS9b36itgnUR2YVH3Wwgtryjh6iP1U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6SN1YuLHe4dR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "id": "57NNUBaHelxc"
   },
   "outputs": [],
   "source": [
    "#convert to pdf\n",
    "%%capture\n",
    "# the red text is a placeholder! Change it to your directory structure!\n",
    "!cp 'drive/My Drive/Colab Notebooks/4740_FA20_p2_yl2546_zz727.ipynb' ./ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "id": "yi1AV8wces0M"
   },
   "outputs": [],
   "source": [
    "# the red text is a placeholder! Change it to the name of this notebook!\n",
    "# !jupyter nbconvert --to PDF \"4740_FA20_p2_yl2546_zz727.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EHrCSEdyEnM"
   },
   "source": [
    "#Appendix\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9A79lUrs9xU"
   },
   "source": [
    "### Tentative grading guideline\n",
    "\n",
    "- (5 pts) Dataset exploration.\n",
    "- (20 pts) Design and implementation of the HMM model. Specifically, calculations of emission/transition probability, smoothing, handling of unknown words.\n",
    "- (20 pts) Design and implementation of the MEMM, as well as the feature set and how the feature extraction is done.\n",
    "- (20 pts) Experiment design and methodology. Investigations into feature sets and unknown word handling/smoothing.\n",
    "- (20 pts) Error analysis and comparison of **HMM** model with the **MEMM**. \n",
    "- (10 pts) Report: organization, clarity and including the **corresponding pieces of code for the implementations**.\n",
    "- (5 pts) **Submission to Kaggle**. In the report, you should add a screenshot of your team’s performance on kaggle leaderboard.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4740_FA20_p2_yl2546_zz727.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
